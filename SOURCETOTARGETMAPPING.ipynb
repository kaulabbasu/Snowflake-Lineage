{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "d2yuo57c5bxuysjgjlph",
   "authorId": "660919035255",
   "authorName": "BASUK",
   "authorEmail": "basuk@vrtx.com",
   "sessionId": "92e9c7d8-da93-47f0-9914-a7020ceed830",
   "lastEditTime": 1756375183435
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "ImportPackages",
    "collapsed": false,
    "codeCollapsed": false
   },
   "source": "# Import python packages\nimport snowflake.connector\nfrom snowflake.connector import DictCursor\nimport pandas as pd\nfrom snowflake.connector.pandas_tools import write_pandas\nimport time\nimport sys\n\n# We can also use Snowpark for our analyses!\n# from snowflake.snowpark.context import get_active_session\n# session = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "baace292-e29f-4369-81f6-48979bcbb2d6",
   "metadata": {
    "language": "python",
    "name": "Parameters",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "user = sys.argv[0].split(',')[0] if sys.argv[0].count(',')>=2 else 'BASUK'\nprint(f\"snowflake user : {user}\")\ndatabase = sys.argv[0].split(',')[2] if sys.argv[0].count(',')>=2 else 'DEV_P_CMSC_CMO_DB'\nprint(f\"snowflake database : {database}\")\nwarehouse = sys.argv[0].split(',')[1] if sys.argv[0].count(',')>=2 else 'DEV_CMSC_CMO_WH'\nprint(f\"snowflake warehouse : {warehouse}\")\nschemas = sys.argv[0].split(',')[3:] if sys.argv[0].count(',')>=3 else ['MODELED','REPORTING']\nprint(f\"snowflake schemas : {schemas}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "DefineLineageFields",
    "codeCollapsed": false,
    "collapsed": false
   },
   "source": "printLINEAGE_COLUMNS = [\n    'ROOT_DATABASE',\n    'ROOT_SCHEMA',\n    'ROOT_TABLE',\n    'ROOT_COLUMN',\n    'DISTANCE',\n    'SOURCE_OBJECT_DOMAIN',\n    'SOURCE_OBJECT_DATABASE',\n    'SOURCE_OBJECT_SCHEMA',\n    'SOURCE_OBJECT_NAME',\n    'SOURCE_COLUMN_NAME',\n    'SOURCE_IS_IDENTITY',\n    'SOURCE_IS_NULLABLE',\n    'SOURCE_DATA_TYPE',\n    'SOURCE_CHARACTER_MAXIMUM_LENGTH',\n    'SOURCE_NUMERIC_PRECISION',\n    'SOURCE_NUMERIC_SCALE',\n    'SOURCE_COMMENT',\n    'SOURCE_STATUS',\n    'TARGET_OBJECT_DOMAIN',\n    'TARGET_OBJECT_DATABASE',\n    'TARGET_OBJECT_SCHEMA',\n    'TARGET_OBJECT_NAME',\n    'TARGET_COLUMN_NAME',\n    'TARGET_IS_IDENTITY',\n    'TARGET_IS_NULLABLE',\n    'TARGET_DATA_TYPE',\n    'TARGET_CHARACTER_MAXIMUM_LENGTH',\n    'TARGET_NUMERIC_PRECISION',\n    'TARGET_NUMERIC_SCALE',\n    'TARGET_COMMENT',\n    'TARGET_STATUS'\n]\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "FetchCusror",
    "collapsed": false,
    "codeCollapsed": false
   },
   "source": "def get_cursor(conn):\n    return conn.cursor(DictCursor)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "19b91a44-33cc-4052-9904-b21f5277cccc",
   "metadata": {
    "language": "python",
    "name": "FetchFields",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def get_columns(conn, database, schemas) -> list:\n    cur = get_cursor(conn)\n\n    column_sql = f\"\"\"\n        select table_catalog, table_schema, table_name, column_name, ordinal_position\n        from {database}.INFORMATION_SCHEMA.COLUMNS\n        where 1=1\n    \"\"\"\n\n    if schemas:\n        quoted_schemas = [\n            \"'\" + str(schema).upper() + \"'\" for schema in schemas]\n        column_sql += f\"\"\"\n        and table_schema in ({','.join(quoted_schemas)})\n        \"\"\"\n\n    column_sql += f\"\"\"\n        order by table_catalog, table_schema, table_name, ordinal_position\n    \"\"\"\n\n    columns = cur.execute(column_sql).fetchall()\n    return columns",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ec33628-61b5-445f-8620-c346dd6ce300",
   "metadata": {
    "language": "python",
    "name": "FetchFieldLineageQuery",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def get_column_lineage_sql(column, with_order_by=True):\n    domain = f\"'{column.get('TABLE_CATALOG')}.{column.get('TABLE_SCHEMA')}.{column.get('TABLE_NAME')}.{column.get('COLUMN_NAME')}'\"\n\n    order_by = \"\"\n    if with_order_by:\n        order_by = \"ORDER BY DISTANCE\"\n\n    lineage_sql = f\"\"\"\n        SELECT\n            DISTANCE,\n            SOURCE_OBJECT_DOMAIN,\n            SOURCE_OBJECT_DATABASE,\n            SOURCE_OBJECT_SCHEMA,\n            SOURCE_OBJECT_NAME,\n            SOURCE_COLUMN_NAME,\n            SOURCE_STATUS,\n            TARGET_OBJECT_DOMAIN,\n            TARGET_OBJECT_DATABASE,\n            TARGET_OBJECT_SCHEMA,\n            TARGET_OBJECT_NAME,\n            TARGET_COLUMN_NAME,\n            TARGET_STATUS,\n            '{column.get('TABLE_CATALOG')}' as ROOT_DATABASE,\n            '{column.get('TABLE_SCHEMA')}' as ROOT_SCHEMA,\n            '{column.get('TABLE_NAME')}' as ROOT_TABLE,\n            '{column.get('COLUMN_NAME')}' as ROOT_COLUMN\n        FROM TABLE (SNOWFLAKE.CORE.GET_LINEAGE({domain}, 'COLUMN', 'UPSTREAM'))\n        {order_by}\n    \"\"\"\n\n    return lineage_sql\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fcf342db-7111-4ea1-8e4c-8ebcdf75d8e0",
   "metadata": {
    "language": "python",
    "name": "FetchFieldMetadata",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "column_metadata_cache = {}\n\n\ndef get_column_metadata(conn, database, schema, table, column, type):\n    cur = get_cursor(conn)\n\n    cache_key = f\"{type}:{database}.{schema}\".upper()\n\n    if not cache_key in column_metadata_cache:\n        print(f\"Cache miss for cache_key: {cache_key}\")\n\n        query = f\"\"\"\n            select\n                table_name as TABLE_NAME,\n                column_name as COLUMN_NAME,\n                '{type}' as COLUMN_TYPE,\n                is_identity as {type}_IS_IDENTITY,\n                \n                is_nullable as {type}_IS_NULLABLE,\n                data_type as {type}_DATA_TYPE,\n                character_maximum_length as {type}_CHARACTER_MAXIMUM_LENGTH,\n                numeric_precision as {type}_NUMERIC_PRECISION,\n                numeric_scale as {type}_NUMERIC_SCALE,\n                comment as {type}_COMMENT\n            from {database}.INFORMATION_SCHEMA.COLUMNS\n            where table_catalog = '{database}'\n            and table_schema = '{schema}'\n        \"\"\"\n\n        column_metadata = cur.execute(query).fetchall()\n        column_metadata_cache[cache_key] = column_metadata\n\n    column_data = next((x for x in column_metadata_cache[cache_key] if x.get(\n        \"TABLE_NAME\") == table and x.get(\"COLUMN_NAME\") == column and x.get(\"COLUMN_TYPE\") == type))\n\n    # Need a copy to not alter the cache\n    column_data_copy = column_data.copy()\n    if column_data_copy:\n        # Have to delete these keys because we don't want it on the final output\n        del column_data_copy[\"TABLE_NAME\"]\n        del column_data_copy[\"COLUMN_NAME\"]\n        del column_data_copy[\"COLUMN_TYPE\"]\n\n    return column_data_copy\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "305ef42f-c7a4-4814-a8fb-89cb5615f879",
   "metadata": {
    "language": "python",
    "name": "FetchFieldLineage",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def get_column_lineage(conn, column):\n    cur = get_cursor(conn)\n\n    lineage_sql = get_column_lineage_sql(column)\n\n    lineage = cur.execute(lineage_sql).fetchall()\n    return lineage",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6984ac15-efde-4a7f-8a94-62995d03e764",
   "metadata": {
    "language": "python",
    "name": "FetchFieldLineageResults",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def get_column_lineage_results(conn, sfqid):\n    cur = get_cursor(conn)\n\n    cur.get_results_from_sfqid(sfqid)\n    lineage = cur.fetchall()\n    return lineage",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56969cf3-1e24-40c5-89e2-ad3f39409455",
   "metadata": {
    "language": "python",
    "name": "CheckQueryCompletion",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def check_if_query_complete(conn, sfqid):\n    is_running = conn.is_still_running(conn.get_query_status(sfqid))\n    return not is_running\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47b2ad15-448b-4aa2-80fb-e1926fabff81",
   "metadata": {
    "language": "python",
    "name": "FetchFieldLineageAsync",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def get_column_lineage_async(conn, column):\n    cur = get_cursor(conn)\n\n    lineage_sql = get_column_lineage_sql(column)\n\n    cur.execute_async(lineage_sql)\n\n    return cur.sfqid",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f6ace869-e3f7-4667-a912-13f719350a87",
   "metadata": {
    "language": "python",
    "name": "DropExistingMapping",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def drop_table(user, database, schema, table, warehouse):\n    '''Drop the existing mapping table so that it can be recreated'''\n    con = snowflake.connector.connect(\n        user=user,\n        authenticator=\"externalBrowser\",\n        account='vrtx-data',\n        database=database,\n        warehouse=warehouse,\n        client_session_keep_alive=True,\n        client_fetch_use_mp=True\n    )\n    table_name = f'{database}.{schema}.{table}'\n    cur = con.cursor()\n    drop_query = f\"DROP TABLE IF EXISTS {table_name};\"\n    cur.execute(drop_query)\n    cur.close()\n    con.close()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "80425496-33a4-418a-aa4d-970bbf0af178",
   "metadata": {
    "language": "python",
    "name": "FetchChunks",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def chunks(lst, n):\n    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n    for i in range(0, len(lst), n):\n        yield lst[i:i + n]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ab32c363-7840-48b1-a986-612a67038a2c",
   "metadata": {
    "language": "python",
    "name": "Main",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "if __name__ == \"__main__\":\n    # parser = argparse.ArgumentParser()\n    # parser.add_argument(\"-d\", \"--database\", default = \"DEV_P_CMSC_CMO_DB\",\n    #                     help=\"Snowflake database for connection\")\n    # parser.add_argument(\"-s\", \"--schemas\",\n    #                     help=\"Snowflake schema for connection.  Provide comma separated list to filter to specific schemas.\", default=\"reporting,modeled\")\n    # parser.add_argument(\"-w\", \"--warehouse\",\n    #                     help=\"Snowflake warehouse for connection\", default=\"DEV_CMSC_CMO_WH\")\n    # args = parser.parse_args()\n    args = {'user':user,'database':database,'warehouse':warehouse,'schemas':schemas}\n    print(args)\n    conn = snowflake.connector.connect(\n        user=user,\n        authenticator=\"externalBrowser\",\n        account='vrtx-data',\n        database=args['database'],\n        warehouse=args['warehouse'],\n        client_session_keep_alive=True,\n        client_fetch_use_mp=True\n    )\n    # schemas = args['schemas'].split(',')\n    columns: list = get_columns(conn, args['database'], schemas)\n    # user_schema = f'DBT_{user}'\n    try:\n        # drop_table('DEV_P_CMSC_CMO_DB.DBT_KBASU.MAPPING')\n        drop_table(user, database,'ARTIFACTS','LINEAGE',warehouse)\n    except Exception as e:\n        print(e)\n    q = []\n    for column_subset in chunks(columns, 50):\n            sfqids = []\n            for column in column_subset:\n                domain = f\"'{column.get('TABLE_CATALOG')}.{column.get('TABLE_SCHEMA')}.{column.get('TABLE_NAME')}.{column.get('COLUMN_NAME')}'\"\n                print(f\"Submitting lineage SQL for {domain}\")\n                sfqids.append(get_column_lineage_async(conn, column))\n            query_results = []\n            while len(sfqids):\n                print(\n                    f\"# of unfinished lineage SQL queries: {len(sfqids)}\")\n                sfqid = sfqids[0]\n                is_complete = check_if_query_complete(conn, sfqid)\n                if is_complete:\n                    lineage_records = get_column_lineage_results(conn, sfqid)\n                    for record in lineage_records:\n                        source_column_metadata = get_column_metadata(\n                            conn=conn,\n                            database=record.get('SOURCE_OBJECT_DATABASE'),\n                            schema=record.get('SOURCE_OBJECT_SCHEMA'),\n                            table=record.get('SOURCE_OBJECT_NAME'),\n                            column=record.get('SOURCE_COLUMN_NAME'),\n                            type=\"SOURCE\"\n                        )\n                        target_column_metadata = get_column_metadata(\n                            conn=conn,\n                            database=record.get('TARGET_OBJECT_DATABASE'),\n                            schema=record.get('TARGET_OBJECT_SCHEMA'),\n                            table=record.get('TARGET_OBJECT_NAME'),\n                            column=record.get('TARGET_COLUMN_NAME'),\n                            type=\"TARGET\"\n                        )\n                        record = record | source_column_metadata | target_column_metadata\n                        query_results.append(record)\n                    sfqids.pop(0)\n                else:\n                    time.sleep(5)\n            df = pd.DataFrame(query_results)\n            #Write the fresh mapping\n            try:\n                        write_pandas(\n                            conn=conn,\n                            df=df,\n                            database=database,\n                            schema='ARTIFACTS',\n                            table_name='LINEAGE',\n                            auto_create_table=True)\n                        print(f'Check {database}.ARTIFACTS.LINEAGE table for source to target mapping details')\n            except Exception as e:\n                        print(e)",
   "execution_count": null
  }
 ]
}